{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process _machines19thC_ dataset\n",
    "\n",
    "**TO DO:** Provide instructions to get `../resources/machines19thC.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tools import animacy_evaluation,processing\n",
    "import operator\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Load and process machines19thC annotations:\n",
    "\n",
    "master_all = pd.read_csv(\"../resources/machines19thC.tsv\", sep=\"\\t\", index_col=0)\n",
    "master_all[[\"prevSentence\", \"currentSentence\", \"maskedSentence\", \"nextSentence\"]] = master_all.apply(lambda row: pd.Series(processing.processMachines19thC(row['Sentence'], row['SentenceCtxt'], row['TargetExpression'], nlp)), axis=1)\n",
    "master_all = master_all.rename(columns={\"TargetExpression\": \"targetExpression\"})\n",
    "master_all = master_all[master_all[\"maskedSentence\"].str.contains(\"[MASK]\", regex=False)]\n",
    "master_all[['context3wmasked', 'context3w']] = master_all.apply(lambda row: pd.Series(processing.ngram_context(row['maskedSentence'], row['targetExpression'], 3)), axis=1)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Separate animacy and humanness annotations:\n",
    "\n",
    "# Animacy:\n",
    "animacy_all = pd.DataFrame()\n",
    "cols = [\"Date\",\"SentenceId\",\"prevSentence\",\"currentSentence\",\"maskedSentence\",\"nextSentence\",\"targetExpression\",\"context3wmasked\",\"context3w\"]\n",
    "animacy_all = master_all[cols + [\"animacy_majority\"]]\n",
    "animacy_all = animacy_all.rename(columns={\"animacy_majority\": \"animated\", \"Date\": \"date\"})\n",
    "animacy_all = animacy_all[animacy_all[\"animated\"].notnull()]\n",
    "animacy_all = animacy_all.reset_index()\n",
    "animacy_all[\"animated\"] = animacy_all[\"animated\"].astype('int64')\n",
    "\n",
    "# Humanness:\n",
    "humanness_all = pd.DataFrame()\n",
    "humanness_all = master_all[cols]\n",
    "humanness_all = master_all[cols + [\"humanness_majority\"]]\n",
    "humanness_all = humanness_all.rename(columns={\"animacy_majority\": \"animated\", \"Date\": \"date\"})\n",
    "humanness_all = humanness_all.rename(columns={\"humanness_majority\": \"animated\"})\n",
    "humanness_all = humanness_all[humanness_all[\"animated\"].notnull()]\n",
    "humanness_all = humanness_all.reset_index()\n",
    "humanness_all[\"animated\"] = humanness_all[\"animated\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdf_animacy = \"../data/machines19thC_animacy/\"\n",
    "Path(pathdf_animacy).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Store machines19thC animacy dataframe:\n",
    "animacy_all = animacy_all.drop(\"index\", axis=1)\n",
    "animacy_all.to_pickle(pathdf_animacy + \"animacy.pkl\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Split into train and test set and store:\n",
    "\n",
    "trainsplit = 0.3\n",
    "\n",
    "animacy_all = animacy_all.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "animacy_all_train_set = animacy_all.sample(frac=trainsplit, random_state=0)\n",
    "animacy_all_test_set = animacy_all[~animacy_all.index.isin(animacy_all_train_set.index)]\n",
    "\n",
    "animacy_all_train_set.to_pickle(pathdf_animacy + \"train.pkl\")\n",
    "animacy_all_test_set.to_pickle(pathdf_animacy + \"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdf_humanness = \"../data/machines19thC_humanness/\"\n",
    "Path(pathdf_humanness).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Store machines19thC humanness dataframe:\n",
    "humanness_all = humanness_all.drop(\"index\", axis=1)\n",
    "humanness_all.to_pickle(pathdf_humanness + \"humanness.pkl\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Split into train and test set and store:\n",
    "\n",
    "trainsplit = 0.3\n",
    "\n",
    "humanness_all = humanness_all.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "humanness_all_train_set = humanness_all.sample(frac=trainsplit, random_state=0)\n",
    "humanness_all_test_set = humanness_all[~humanness_all.index.isin(animacy_all_train_set.index)]\n",
    "\n",
    "humanness_all_train_set.to_pickle(pathdf_humanness + \"train.pkl\")\n",
    "humanness_all_test_set.to_pickle(pathdf_humanness + \"test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train annd test sets\n",
      "====================\n",
      "Animacy train set: {0: 113, 1: 65}\n",
      "Animacy test set: {0: 279, 1: 136}\n",
      "\n",
      "Number of rows\n",
      "==============\n",
      "All rows:\n",
      "* All: 593\n",
      "* Train: 178\n",
      "* Test: 415\n"
     ]
    }
   ],
   "source": [
    "print(\"Train annd test sets\")\n",
    "print(\"====================\")\n",
    "print(\"Animacy train set:\", animacy_all_train_set.animated.value_counts().to_dict())\n",
    "print(\"Animacy test set:\", animacy_all_test_set.animated.value_counts().to_dict())\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Annotation counts:\n",
    "\n",
    "print(\"\\nNumber of rows\")\n",
    "print(\"==============\")\n",
    "print(\"All rows:\")\n",
    "print(\"* All:\", animacy_all.animated.count())\n",
    "print(\"* Train:\", animacy_all_train_set.animated.count())\n",
    "print(\"* Test:\", animacy_all_test_set.animated.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***prevSentence*** There is also a hook and ladder company.\n",
      "***currentSentence*** The engine house, which is a neat, two-story structure, of brick, was built in 1874, at a cost of $5,000 In the second story are the firemen's hall, City Hall and municipal offices, and in the basement, the jail.\n",
      "***maskedSentence*** The [MASK] house, which is a neat, two-story structure, of brick, was built in 1874, at a cost of $5,000 In the second story are the firemen's hall, City Hall and municipal offices, and in the basement, the jail.\n",
      "***nextSentence*** The present chief of the depart ment is Julius Pelz.\n",
      "***targetExpression*** engine\n",
      "***context3wmasked*** The [MASK] house, which is\n",
      "***context3w*** The engine house, which is\n",
      "***animated*** 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(pathdf_animacy + \"train.pkl\")\n",
    "\n",
    "sentInd = 1\n",
    "print(\"***prevSentence***\", df.iloc[sentInd].prevSentence)\n",
    "print(\"***currentSentence***\", df.iloc[sentInd].currentSentence)\n",
    "print(\"***maskedSentence***\", df.iloc[sentInd].maskedSentence)\n",
    "print(\"***nextSentence***\", df.iloc[sentInd].nextSentence)\n",
    "print(\"***targetExpression***\", df.iloc[sentInd].targetExpression)\n",
    "print(\"***context3wmasked***\", df.iloc[sentInd].context3wmasked)\n",
    "print(\"***context3w***\", df.iloc[sentInd].context3w)\n",
    "print(\"***animated***\", df.iloc[sentInd].animated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.336 r: 0.5 macro_f1: 0.402 micro_f1: 0.672 map: 0.318\n"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.read_pickle(pathdf_animacy + \"test.pkl\")\n",
    "classes_by_frequency = dataset_df.animated.value_counts(normalize=True).to_dict()\n",
    "most_frequent_class = max(classes_by_frequency.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "y_pred = [int(most_frequent_class) for x in dataset_df['animated'].tolist()]\n",
    "y_true = [int(x) for x in dataset_df['animated'].tolist()]\n",
    "\n",
    "precision, recall, fscore, micro_fscore, map_ = animacy_evaluation.results(y_true,y_pred,0.5)\n",
    "print(\"p:\", round(precision,3), \"r:\", round(recall,3), \"macro_f1:\", round(fscore,3), \"micro_f1:\", round(micro_fscore,3), \"map:\", round(map_,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create combined training set (`stories` and `machines19thC`)\n",
    "\n",
    "Make sure you have run `process_stories_dataset.ipynb` before you run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpstories = pd.read_pickle(\"../data/stories/train.pkl\")\n",
    "tmpstories = tmpstories.drop(\"storyNumber\", axis=1)\n",
    "tmpmachines = pd.read_pickle(\"../data/machines19thC_animacy/train.pkl\")\n",
    "tmpmachines = tmpmachines.drop([\"date\", \"SentenceId\"], axis=1)\n",
    "combineddf = pd.concat([tmpstories, tmpmachines], ignore_index=True, sort=True)\n",
    "combineddf = combineddf.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "pathcomb = \"../data/combined/\"\n",
    "Path(pathcomb).mkdir(parents=True, exist_ok=True)\n",
    "combineddf.to_pickle(pathcomb + \"train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lwmbert)",
   "language": "python",
   "name": "lwmbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
