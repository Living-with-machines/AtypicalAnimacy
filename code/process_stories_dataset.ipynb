{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process _Stories_ dataset\n",
    "\n",
    "Prepare dataset from COLING 2018 paper:\n",
    "> Jahan, Labiba, Geeticka Chauhan, and Mark Finlayson. \"A new approach to animacy detection.\" In _Proceedings of the 27th International Conference on Computational Linguistics_, pp. 1-12. 2018.\n",
    "\n",
    "Download data from https://dspace.mit.edu/handle/1721.1/116172, unzip it, and store it in `../resources/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tools import animacy_evaluation,processing\n",
    "\n",
    "import spacy\n",
    "import operator\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse corpus into sentence-level dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_animacy_xml(animacy_file):\n",
    "    tree = ET.parse(animacy_file)\n",
    "    story = tree.getroot()\n",
    "    fulltext = \"\"\n",
    "    storyNumber = animacy_file.split(\"/\")[-1].split(\".sty\")[0]\n",
    "    \n",
    "    dTokens = dict()\n",
    "    dRefExp = dict()\n",
    "    dCorExp = dict()\n",
    "    \n",
    "    dAnimacyExpressions = dict()\n",
    "    processed_annotations = []\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # Capture relevant data from xml: token, refering expression, and coreferent\n",
    "    # expression annotated with animacy.\n",
    "    for section in story:\n",
    "        if section.attrib['id'] == 'edu.mit.parsing.token':\n",
    "            for child in section.findall('./desc'):\n",
    "                dTokens[child.attrib['id']] = child.text.strip()\n",
    "                \n",
    "        if section.attrib['id'] == 'edu.mit.discourse.rep.refexp':\n",
    "            for child in section.findall('./desc'):\n",
    "                reftokens = []\n",
    "                offset = int(child.attrib['off'])\n",
    "                grouped = child.text.split(\",\")\n",
    "                for gr in grouped:\n",
    "                    reftokens.append(gr.split(\"~\"))\n",
    "                dRefExp[child.attrib['id']] = (child.text, reftokens)\n",
    "                        \n",
    "        if section.attrib['id'] == 'edu.mit.discourse.rep.coref':\n",
    "            for child in section.findall('./desc'):\n",
    "                offset = int(child.attrib['off'])\n",
    "                text2mask = child.text.split(\"|\")[0]\n",
    "                coref_ani = 0\n",
    "                if 'ani' in child.attrib:\n",
    "                    if child.attrib['ani'] == '1':\n",
    "                        coref_ani = 1\n",
    "                \n",
    "                dCorExp[child.attrib['id']] = (child.text, coref_ani)\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # Capture referring expressions whose coreferent is annotated with animacy\n",
    "    for corefExp in dCorExp:\n",
    "        coref_ani = dCorExp[corefExp][1]\n",
    "        coreftext, refids = dCorExp[corefExp][0].split(\"|\")\n",
    "        refids = refids.split(\",\")\n",
    "        for refid in refids:\n",
    "            for sq in dRefExp[refid][1]:\n",
    "                dAnimacyExpressions[tuple(sq)] = ([dTokens[tk] for tk in sq], coref_ani)\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # Add sentence index to each token\n",
    "    fulltext = [dTokens[t] for t in dTokens]\n",
    "    \n",
    "    tokens_in_sentence = dict()\n",
    "    sIndex = 0\n",
    "    sentences = sent_tokenize(\" \".join(fulltext))\n",
    "    sentences_indices = []\n",
    "    dSentences = dict()\n",
    "    \n",
    "    for s in sentences:\n",
    "        sIndex += 1\n",
    "        sentences_indices.append((s, sIndex))\n",
    "        dSentences[sIndex] = s\n",
    "    \n",
    "    current_sentence = sentences_indices[0][0].split(\" \")\n",
    "    for t in dTokens:\n",
    "        if dTokens[t] == current_sentence[0]:\n",
    "            tokens_in_sentence[t] = (dTokens[t], sentences_indices[0][1])\n",
    "            del current_sentence[0]\n",
    "            if len(current_sentence) == 0:\n",
    "                del sentences_indices[0]\n",
    "                if sentences_indices:\n",
    "                    current_sentence = sentences_indices[0][0].split(\" \")\n",
    "        else:\n",
    "            tokens_in_sentence[t] = (dTokens[t], None)\n",
    "    \n",
    "    dSentenceIndices = dict()\n",
    "    for tk in tokens_in_sentence:\n",
    "        word_index = tk\n",
    "        sent_index = tokens_in_sentence[tk][1]\n",
    "        if sent_index in dSentenceIndices:\n",
    "            dSentenceIndices[sent_index].append(word_index)\n",
    "        else:\n",
    "            dSentenceIndices[sent_index] = [word_index]\n",
    "        \n",
    "    # ------------------------------------------------------\n",
    "    # Recover sentence where animated expression occurs, and its context\n",
    "    for expression in dAnimacyExpressions:\n",
    "        sentences_involved = list(set([tokens_in_sentence[e][1] for e in expression]))\n",
    "        sentence = 0\n",
    "        if len(sentences_involved) > 1: # Discard multisentence expressions, often annotation errors it seems\n",
    "            continue\n",
    "        else:\n",
    "            sentence = sentences_involved[0]\n",
    "        \n",
    "        token_expression = dAnimacyExpressions[expression][0]\n",
    "        animacy = dAnimacyExpressions[expression][1]\n",
    "        \n",
    "        words_sentence = dSentences[sentence].split()\n",
    "        index_sentence = dSentenceIndices[sentence]\n",
    "        \n",
    "        # ------------------------------------------------------\n",
    "        # Find each item of the target expression in the current sentence, and mask it\n",
    "        masked_sentence = []\n",
    "        if len(words_sentence) == len(index_sentence):\n",
    "            zipped_sentence = list(zip(dSentenceIndices[sentence], dSentences[sentence].split()))\n",
    "            indexExp = 0\n",
    "            for z in zipped_sentence:\n",
    "                if indexExp < len(expression):\n",
    "                    if z[0] == expression[indexExp] and z[1] == token_expression[indexExp]:\n",
    "                        masked_sentence.append(\"[MASK]\")\n",
    "                        indexExp += 1\n",
    "                    else:\n",
    "                        masked_sentence.append(z[1])\n",
    "                else:\n",
    "                    masked_sentence.append(z[1])\n",
    "        \n",
    "        # ------------------------------------------------------\n",
    "        # Relevant outputs:\n",
    "        prev_sentence = dSentences.get(sentence - 1, \"\")\n",
    "        current_sentence = dSentences[sentence]\n",
    "        target_expression = \" \".join(dAnimacyExpressions[expression][0]).strip()\n",
    "        masked_sentence = \" \".join(masked_sentence)\n",
    "        next_sentence = dSentences.get(sentence + 1, \"\")\n",
    "        # Replace a multi-token masked expression to just one mask, instead of\n",
    "        # having consecutive masked elements. E.g. Instead of \"[MASK] [MASK] [MASK]\n",
    "        # drank\" for \"A little man drank\", replace to \"[MASK] drank\":\n",
    "        regex_mask = r\"( ?\\[MASK\\] ?\\-?)+\" \n",
    "        masked_sentence = re.sub(regex_mask, \" [MASK] \", masked_sentence).strip()\n",
    "        \n",
    "        # ------------------------------------------------------\n",
    "        # Append relevant outputs to list to return:\n",
    "        if masked_sentence.count(\"[MASK]\") == 1: # This line is to filter out some inconsistencies in the data\n",
    "            processed_annotations.append((storyNumber, prev_sentence, current_sentence, masked_sentence, next_sentence, target_expression, animacy))\n",
    "    \n",
    "    return processed_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Process Jahan animacy corpus, turn it to Stories corpus:\n",
    "storiesdf = pd.DataFrame()\n",
    "for i in glob.glob(\"../resources/jahan_animacy_v1.0.0/jahan_animacy_corpus_v1.0.0/data/*\"):\n",
    "    processed_annotations = parse_animacy_xml(i)\n",
    "    localdf = pd.DataFrame(processed_annotations, columns=[\"storyNumber\", \"prevSentence\", \"currentSentence\", \"maskedSentence\", \"nextSentence\", \"targetExpression\", \"animated\"])\n",
    "    storiesdf = pd.concat([storiesdf, localdf], ignore_index=True)\n",
    "    \n",
    "storiesdf[['maskedSentence', 'targetExpression']] = storiesdf.apply(lambda row: pd.Series(processing.processStories(row['targetExpression'], row['maskedSentence'], nlp)), axis=1)\n",
    "storiesdf[['context3wmasked', 'context3w']] = storiesdf.apply(lambda row: pd.Series(processing.ngram_context(row['maskedSentence'], row['targetExpression'], 3)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Store stories dataframe:\n",
    "pathdf = \"../data/stories/\"\n",
    "Path(pathdf).mkdir(parents=True, exist_ok=True)\n",
    "storiesdf.to_pickle(pathdf + \"all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsplit = 0.7\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Split stories into training and test set, and store:\n",
    "train = storiesdf.reset_index(\n",
    "    ).groupby('animated'\n",
    "    ).apply(lambda x: x.sample(frac=trainsplit, random_state=0)\n",
    "    ).reset_index(drop=True\n",
    "    ).set_index('index')\n",
    "test = storiesdf.drop(train.index)\n",
    "train = train.sample(frac=1)\n",
    "test = test.sample(frac=1)\n",
    "\n",
    "train_set = train\n",
    "test_set = test\n",
    "\n",
    "train_set.to_pickle(\"../data/stories/all_train.pkl\")\n",
    "test_set.to_pickle(\"../data/stories/all_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyNumber</th>\n",
       "      <th>prevSentence</th>\n",
       "      <th>currentSentence</th>\n",
       "      <th>maskedSentence</th>\n",
       "      <th>nextSentence</th>\n",
       "      <th>targetExpression</th>\n",
       "      <th>animated</th>\n",
       "      <th>context3wmasked</th>\n",
       "      <th>context3w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story32</td>\n",
       "      <td></td>\n",
       "      <td>Once upon a time there lived a king and queen .</td>\n",
       "      <td>Once upon a time there lived a [MASK] and queen .</td>\n",
       "      <td>They had three sons , two of them with their w...</td>\n",
       "      <td>king</td>\n",
       "      <td>1</td>\n",
       "      <td>there lived a [MASK] and queen .</td>\n",
       "      <td>there lived a king and queen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story32</td>\n",
       "      <td>They had three sons , two of them with their w...</td>\n",
       "      <td>Now the King had a deer-park in which were qua...</td>\n",
       "      <td>Now the [MASK] had a deer-park in which were q...</td>\n",
       "      <td>Into that park there used to come a huge beast...</td>\n",
       "      <td>King</td>\n",
       "      <td>1</td>\n",
       "      <td>Now the [MASK] had a deer-park</td>\n",
       "      <td>Now the King had a deer-park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>story32</td>\n",
       "      <td>Into that park there used to come a huge beast...</td>\n",
       "      <td>The King did all he could , but he was unable ...</td>\n",
       "      <td>The [MASK] did all he could , but he was unabl...</td>\n",
       "      <td>So at last he called his sons together and sai...</td>\n",
       "      <td>King</td>\n",
       "      <td>1</td>\n",
       "      <td>The [MASK] did all he</td>\n",
       "      <td>The King did all he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story32</td>\n",
       "      <td>Into that park there used to come a huge beast...</td>\n",
       "      <td>The King did all he could , but he was unable ...</td>\n",
       "      <td>The King did all [MASK] could , but he was una...</td>\n",
       "      <td>So at last he called his sons together and sai...</td>\n",
       "      <td>he</td>\n",
       "      <td>0</td>\n",
       "      <td>King did all [MASK] could , but</td>\n",
       "      <td>King did all he could , but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story32</td>\n",
       "      <td>The King did all he could , but he was unable ...</td>\n",
       "      <td>So at last he called his sons together and sai...</td>\n",
       "      <td>So at last he called [MASK] sons together and ...</td>\n",
       "      <td>Well , the eldest son undertook the task .</td>\n",
       "      <td>his</td>\n",
       "      <td>0</td>\n",
       "      <td>last he called [MASK] sons together and</td>\n",
       "      <td>last he called his sons together and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storyNumber                                       prevSentence  \\\n",
       "0     story32                                                      \n",
       "1     story32  They had three sons , two of them with their w...   \n",
       "2     story32  Into that park there used to come a huge beast...   \n",
       "3     story32  Into that park there used to come a huge beast...   \n",
       "4     story32  The King did all he could , but he was unable ...   \n",
       "\n",
       "                                     currentSentence  \\\n",
       "0    Once upon a time there lived a king and queen .   \n",
       "1  Now the King had a deer-park in which were qua...   \n",
       "2  The King did all he could , but he was unable ...   \n",
       "3  The King did all he could , but he was unable ...   \n",
       "4  So at last he called his sons together and sai...   \n",
       "\n",
       "                                      maskedSentence  \\\n",
       "0  Once upon a time there lived a [MASK] and queen .   \n",
       "1  Now the [MASK] had a deer-park in which were q...   \n",
       "2  The [MASK] did all he could , but he was unabl...   \n",
       "3  The King did all [MASK] could , but he was una...   \n",
       "4  So at last he called [MASK] sons together and ...   \n",
       "\n",
       "                                        nextSentence targetExpression  \\\n",
       "0  They had three sons , two of them with their w...             king   \n",
       "1  Into that park there used to come a huge beast...             King   \n",
       "2  So at last he called his sons together and sai...             King   \n",
       "3  So at last he called his sons together and sai...               he   \n",
       "4         Well , the eldest son undertook the task .              his   \n",
       "\n",
       "   animated                          context3wmasked  \\\n",
       "0         1         there lived a [MASK] and queen .   \n",
       "1         1           Now the [MASK] had a deer-park   \n",
       "2         1                    The [MASK] did all he   \n",
       "3         0          King did all [MASK] could , but   \n",
       "4         0  last he called [MASK] sons together and   \n",
       "\n",
       "                              context3w  \n",
       "0        there lived a king and queen .  \n",
       "1          Now the King had a deer-park  \n",
       "2                   The King did all he  \n",
       "3           King did all he could , but  \n",
       "4  last he called his sons together and  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storiesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train annd test sets\n",
      "====================\n",
      "Animacy train set: {1: 8166, 0: 4929}\n",
      "Animacy test set: {1: 3500, 0: 2113}\n",
      "\n",
      "Number of rows\n",
      "==============\n",
      "All rows:\n",
      "* All: 18708\n",
      "* Train: 13095\n",
      "* Test: 5613\n"
     ]
    }
   ],
   "source": [
    "print(\"Train annd test sets\")\n",
    "print(\"====================\")\n",
    "print(\"Animacy train set:\", train_set.animated.value_counts().to_dict())\n",
    "print(\"Animacy test set:\", test_set.animated.value_counts().to_dict())\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Annotation counts:\n",
    "\n",
    "print(\"\\nNumber of rows\")\n",
    "print(\"==============\")\n",
    "print(\"All rows:\")\n",
    "print(\"* All:\", storiesdf.animated.count())\n",
    "print(\"* Train:\", train_set.animated.count())\n",
    "print(\"* Test:\", test_set.animated.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of class 1 labels\n",
      "============================\n",
      "All rows:\n",
      "* All: 0.62\n",
      "* Train: 0.62\n",
      "* Test: 0.62\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Class 1 proportion per dataset:\n",
    "\n",
    "all_vc = storiesdf.animated.value_counts().to_dict()\n",
    "all_train_vc = train_set.animated.value_counts().to_dict()\n",
    "all_test_vc = test_set.animated.value_counts().to_dict()\n",
    "\n",
    "print(\"Proportion of class 1 labels\")\n",
    "print(\"============================\")\n",
    "print(\"All rows:\")\n",
    "print(\"* All:\", round(all_vc[1] / (all_vc[0] + all_vc[1]),2))\n",
    "print(\"* Train:\", round(all_train_vc[1] / (all_train_vc[0] + all_train_vc[1]),2))\n",
    "print(\"* Test:\", round(all_test_vc[1] / (all_test_vc[0] + all_test_vc[1]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***prevSentence*** said the czar .\n",
      "***currentSentence*** Then he dismissed them all .\n",
      "***maskedSentence*** Then he dismissed [MASK] .\n",
      "***nextSentence*** After some time passed , the czar remembering the seven Simeons , decided to put one of their skills to use .\n",
      "***targetExpression*** them all\n",
      "***context3wmasked*** Then he dismissed [MASK] .\n",
      "***context3w*** Then he dismissed them all .\n",
      "***animated*** 1\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Load a dataset:\n",
    "df = pd.read_pickle(\"../data/stories/all_test.pkl\")\n",
    "\n",
    "sentInd = 21 # Select here one row in the dataframe\n",
    "print(\"***prevSentence***\", df.iloc[sentInd].prevSentence)\n",
    "print(\"***currentSentence***\", df.iloc[sentInd].currentSentence)\n",
    "print(\"***maskedSentence***\", df.iloc[sentInd].maskedSentence)\n",
    "print(\"***nextSentence***\", df.iloc[sentInd].nextSentence)\n",
    "print(\"***targetExpression***\", df.iloc[sentInd].targetExpression)\n",
    "print(\"***context3wmasked***\", df.iloc[sentInd].context3wmasked)\n",
    "print(\"***context3w***\", df.iloc[sentInd].context3w)\n",
    "print(\"***animated***\", df.iloc[sentInd].animated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent class baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.312 r: 0.5 macro_f1: 0.384 micro_f1: 0.624 map: 0.627\n"
     ]
    }
   ],
   "source": [
    "dataset_df = pd.read_pickle(\"../data/stories/all_test.pkl\")\n",
    "classes_by_frequency = dataset_df.animated.value_counts(normalize=True).to_dict()\n",
    "most_frequent_class = max(classes_by_frequency.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "y_pred = [int(most_frequent_class) for x in dataset_df['animated'].tolist()]\n",
    "y_true = [int(x) for x in dataset_df['animated'].tolist()]\n",
    "\n",
    "precision, recall, fscore, micro_fscore, map_ = animacy_evaluation.results(y_true,y_pred,0.5)\n",
    "print(\"p:\", round(precision,3), \"r:\", round(recall,3), \"macro_f1:\", round(fscore,3), \"micro_f1:\", round(micro_fscore,3), \"map:\", round(map_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lwmbert] *",
   "language": "python",
   "name": "conda-env-lwmbert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
