{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask prediction approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the additional resources you will need, to run this script:\n",
    "* **CONTEMPORARY BERT MODEL:** (optional) Download it from https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz, unzip it and save in `../models/language_models/bert_models/`\n",
    "* **HISTORICAL BERT MODELS:** Coming soon.\n",
    "* **SENTENCES TRANSFORMERS BERT:** Download it from https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/bert-base-nli-mean-tokens.zip, unzip it and save in `../models/language_models/bert_models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer,BertForMaskedLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import operator\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from tools import animacy_detection,animacy_evaluation,processing\n",
    "import unidecode\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Choose scenario:\n",
    "\n",
    "prediction_approach = \"bert_masking\"\n",
    "# Options:\n",
    "# * \"bert_masking\" (string):\n",
    "# * \"wemb_baseline\" (string):\n",
    "\n",
    "corpus = \"machines19thC/\"\n",
    "# Options:\n",
    "# * \"stories\" (string):\n",
    "# * \"machines19thC\" (string):\n",
    "\n",
    "context = \"both\"\n",
    "# Options:\n",
    "# * \"both\" (string):\n",
    "# * \"prev\" (string):\n",
    "# * \"next\" (string):\n",
    "# * \"sent\" (string):\n",
    "\n",
    "time_period = \"contemporary\"\n",
    "# Options:\n",
    "# * \"contemporary\" (string):\n",
    "# * \"before1850\" (string):\n",
    "# * \"from1850to1875\" (string):\n",
    "# * \"from1875to1890\" (string):\n",
    "# * \"from1890to1900\" (string):\n",
    "# * \"timeSensitive\" (string):\n",
    "\n",
    "weighted = True\n",
    "# Options:\n",
    "# * True (boolean): \n",
    "# * False (boolean): \n",
    "\n",
    "scenario = \"animacy\"\n",
    "# Options:\n",
    "# * \"animacy\" (string):\n",
    "# * \"humanness\" (string):\n",
    "# * \"\" (string):\n",
    "\n",
    "wsd = \"bert\"\n",
    "# Options:\n",
    "# * \"False\" (string):\n",
    "# * \"bert\" (string):\n",
    "\n",
    "words_cutoff = 250\n",
    "# Words cutoff (integer): number of predictions for a given MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Instantiate default values:\n",
    "scenario = \"all_\" if corpus == \"stories/\" else scenario + \"_all_\"\n",
    "time_period = \"contemporary\" if corpus == \"stories/\" else time_period # If corpus is \"stories\", only \"contemporary\" Bert is meaningful\n",
    "language_model = None\n",
    "\n",
    "bert_models = {\"contemporary\": BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "               , \"before1850\": BertForMaskedLM.from_pretrained(\"../models/language_models/bert_models/FT_bert_base_uncased_before_1850\")\n",
    "               , \"from1850to1875\": BertForMaskedLM.from_pretrained(\"../models/language_models/bert_models/FT_bert_base_uncased_after_1850_before_1875\")\n",
    "               , \"from1875to1890\": BertForMaskedLM.from_pretrained(\"../models/language_models/bert_models/FT_bert_base_uncased_after_1875_before_1890\")\n",
    "               , \"from1890to1900\": BertForMaskedLM.from_pretrained(\"../models/language_models/bert_models/FT_bert_base_uncased_after_1890_before_1900\")\n",
    "              }\n",
    "\n",
    "tokenizer = None\n",
    "if prediction_approach == \"bert_masking\":\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # BERT tokenizer is always the same\n",
    "    \n",
    "if prediction_approach == \"wemb_baseline\":\n",
    "    language_model = FastText.load_fasttext_format('../models/language_models/fastai/cc.en.300.bin')\n",
    "\n",
    "wsdmodel = None\n",
    "if wsd == \"bert\":\n",
    "    wsdmodel = SentenceTransformer('../models/language_models/bert_models/bert-base-nli-mean-tokens')\n",
    "\n",
    "# Load datasets:\n",
    "dataset_testdf = pd.read_pickle(\"../data/\" + corpus + scenario + \"test\" + \".pkl\")\n",
    "dataset_traindf = pd.read_pickle(\"../data/\" + corpus + scenario + \"train\" + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train_path = \"../experiments/\" + corpus + scenario + \"train_\" + context + \"_wordsCutoff\" + str(words_cutoff) + \"_\" + prediction_approach + \"_wsd\" + str(wsd) + \"_\" + time_period + \".pkl\"\n",
    "exp_test_path = \"../experiments/\" + corpus + scenario + \"test_\" + context + \"_wordsCutoff\" + str(words_cutoff) + \"_\" + prediction_approach + \"_wsd\" + str(wsd) + \"_\" + time_period + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animacy_detection.predict_mask_animacy(exp_train_path, dataset_traindf, context, words_cutoff, prediction_approach, wsd, wsdmodel, tokenizer, language_model, bert_models, time_period, overwrite)\n",
    "animacy_detection.predict_mask_animacy(exp_test_path, dataset_testdf, context, words_cutoff, prediction_approach, wsd, wsdmodel, tokenizer, language_model, bert_models, time_period, overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_df = pd.read_pickle(exp_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Find the best cutoff and threshold based on training set\n",
    "cutoff_list = []\n",
    "threshold_list = []\n",
    "\n",
    "dataset_train_df = pd.read_pickle(exp_train_path)\n",
    "cutoff_list = [1, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 250]\n",
    "threshold_list = list(np.arange(0, 1.05, 0.1))\n",
    "\n",
    "df_results_train = pd.DataFrame(columns = ['threshold', 'cutoff', 'precision', 'recall', 'fscore', 'micro_fscore', 'map'])\n",
    "for threshold in threshold_list:\n",
    "    print(threshold)\n",
    "    for exp_cutoff in cutoff_list:\n",
    "        setting = (round(threshold,2),exp_cutoff)\n",
    "        predicted = dataset_train_df['predicted'].tolist()\n",
    "        scores = dataset_train_df['scores'].tolist()\n",
    "\n",
    "        y_pred = [animacy_evaluation.animacy_score(predicted[x], scores[x],weighted,exp_cutoff) for x in range(len(predicted))]\n",
    "        y_true = [x for x in dataset_train_df['animated'].tolist()]\n",
    "\n",
    "        precision, recall, fscore, micro_fscore,map_ = animacy_evaluation.results(y_true,y_pred,threshold)\n",
    "        df_results_train = df_results_train.append({'threshold':threshold, 'cutoff':exp_cutoff, 'precision':round(precision,3), 'recall':round(recall,3), 'fscore':round(fscore,3), 'micro_fscore':round(micro_fscore,3), 'map':round(map_,3)}, ignore_index=True)\n",
    "\n",
    "df_results_train.sort_values(by='fscore', ascending=False).to_csv(\"../experiments/\" + corpus + scenario + \"train_\" + context + \"_wordsCutoff\" + str(words_cutoff) + \"_\" + prediction_approach + \"_wsd\" + str(wsd) + \"_weighted\" + str(weighted) + \"_\" + time_period + \".tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Apply the best cutoff and threshold to the test set\n",
    "\n",
    "# Load the parameters file learned from the train set\n",
    "dataset_test_df = pd.read_pickle(exp_test_path)\n",
    "best_threshold = None\n",
    "best_cutoff = None\n",
    "parameters_file = Path(\"../experiments/\" + corpus + scenario + \"train_\" + context + \"_wordsCutoff\" + str(words_cutoff) + \"_\" + prediction_approach + \"_wsd\" + str(wsd) + \"_weighted\" + str(weighted) + \"_\" + time_period + \".tsv\")\n",
    "if parameters_file.exists():\n",
    "    best_threshold = float(pd.read_csv(parameters_file, sep=\"\\t\").loc[0]['threshold'])\n",
    "    best_cutoff = int(pd.read_csv(parameters_file, sep=\"\\t\").loc[0]['cutoff'])\n",
    "else:\n",
    "    print(\"You haven't found the optimal parameters yet.\")\n",
    "\n",
    "# Apply the best cutoff and threshold to the test set\n",
    "if not best_threshold is None:\n",
    "    df_results_test = pd.DataFrame(columns = ['threshold', 'cutoff', 'precision', 'recall', 'fscore', 'micro_fscore', 'map'])\n",
    "    setting = (best_threshold,best_cutoff)\n",
    "    predicted = dataset_test_df['predicted'].tolist()\n",
    "    scores = dataset_test_df['scores'].tolist()\n",
    "\n",
    "    y_pred = [animacy_evaluation.animacy_score(predicted[x], scores[x],weighted,best_cutoff) for x in range(len(predicted))]\n",
    "    y_true = [x for x in dataset_test_df['animated'].tolist()]\n",
    "\n",
    "    precision, recall, fscore, micro_fscore,map_ = animacy_evaluation.results(y_true,y_pred,best_threshold)\n",
    "    df_results_test = df_results_test.append({'threshold':best_threshold, 'cutoff':best_cutoff, 'precision':round(precision,3), 'recall':round(recall,3), 'fscore':round(fscore,3), 'micro_fscore':round(micro_fscore,3), 'map':round(map_,3)}, ignore_index=True)\n",
    "    df_results_test.sort_values(by='fscore', ascending=False).to_csv(\"../experiments/\" + corpus + scenario + \"test_\" + context + \"_wordsCutoff\" + str(words_cutoff) + \"_\" + prediction_approach + \"_wsd\" + str(wsd) + \"_weighted\" + str(weighted) + \"_\" + time_period + \".tsv\", sep=\"\\t\")\n",
    "        \n",
    "    print(\"\\nContext: \"+context+\"\\nPred_approach: \"+str(prediction_approach)+\"\\nWeighted: \"+str(weighted)+\"\\nTimePeriod: \"+str(time_period)+\"\\nWSD: \" + str(wsd) + \"\\n\\n(t=\" + str(round(best_threshold,2)) + \", c=\" + str(int(best_cutoff)) + \") & \" + str(round(precision,3)) + \" & \" + str(round(recall,3)) + \" & \" + str(round(fscore,3)) + \" & \" + str(round(map_, 3)) + \" \\\\\\\\\")\n",
    "\n",
    "    with open(\"../experiments/\" + corpus + scenario + \"results.txt\", \"a\") as fw:\n",
    "        fw.write(\"\\nCorpus: \" + corpus + \"\\nContext: \"+context+\"\\nPred_approach: \"+str(prediction_approach)+\"\\nWeighted: \"+str(weighted)+\"\\nTimePeriod: \"+str(time_period)+\"\\nWSD: \" + str(wsd) + \"\\n\\n(t=\" + str(round(best_threshold,2)) + \", c=\" + str(int(best_cutoff)) + \") & \" + str(round(precision,3)) + \" & \" + str(round(recall,3)) + \" & \" + str(round(fscore,3)) + \" & \" + str(round(map_, 3)) + \" \\\\\\\\\\n\\n==========================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lwmbert] *",
   "language": "python",
   "name": "conda-env-lwmbert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
